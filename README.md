# American-Sign-Language-Recognition

American Sign Language is a natural language that serves as the primary sign language of the deaf communities in America. It has the same linguistic properties as spoken languages, with grammar differing from English. It is expressed by the usersâ€™ movements of the hands and face. To ease the communication between the deaf people and people who do not understand ASL, we have implemented the use of machine learning. We used a pre-existing dataset called [Sign Language MNIST](https://www.kaggle.com/datasets/datamunge/sign-language-mnist), which is presented in CSV formats with labels and pixel values in single rows. The ASL letter database of hand features has 24 classes of letters, excluding letters J and Z as they require motion. The first column contains labels from 0-24, representing A-Y, respectively. The second column onwards contains the pixel value: pixel1 up til pixel784, representing a single 28x28 pixel image with grayscale values between 0-255. The training data has 27,455 cases, and the test data has 7172 cases.
